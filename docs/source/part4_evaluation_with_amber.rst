Part 4: Evaluation with AMBER
=============================

Overview
--------

In this final part, you will evaluate the performance of the binning and refinement steps using AMBER (Assessment of Metagenome BinnERs). Since we have a synthetic dataset with a gold standard, we can compare our bins to the true genomes.

Task 1: Prepare AMBER Input
---------------------------

**Step 1: Organize Binning Results**

Ensure that all binning results are accessible and organized:

.. code-block:: bash

   # Define the binning result directories
   bins_dir="bins"

   # Binning results from individual binners and DAStool
   binners=("metadecoder" "metabat2" "semibin2" "dastool")

   # Paths to binning result files
   # Assuming each binner's bins are in 'bins/<binner>/bins' directory
   # And the contig-to-bin mapping files are in 'bins/<binner>/contig_bins.tsv'
   # DAStool bins are in 'bins/dastool/dastool_DASTool_bins'

**Step 2: Obtain the Gold Standard**

The gold standard mapping file should be provided or known:

.. code-block:: bash

   gold_standard="${course_data_path}/gsa_mapping.tsv"

   # Reformat the gold standard file to be usable by AMBER
   reform_cons_script="${course_path}/scripts/binning_practical/reformat_goldstandard.py"

   python3 "${reform_cons_script}" "${gold_standard}" gold_standard.tsv

   sed -i -e 's/@SampleID:gsa/@SampleID:sample_21/' gold_standard.tsv

   # Inspect the gold standard file
   head -n 10 gold_standard.tsv

**Questions**

- **Q1:** What format is the gold standard file in?
- **Q2:** How are contigs mapped to reference genomes in the gold standard?

Task 3: Run AMBER
-----------------

**Step 1: Execute AMBER**

Run AMBER using the binning results and the gold standard:

.. code-block:: bash

   # Define labels for each binner
   labels="MetaDecoder,MetaBAT2,SemiBin2,DAStool"

   # Prepare amber compatible binning output files for AMBER
   convert_fasta_bins_to_biobox_format.py bins/metadecoder/*.fasta -o bins/metadecoder/cami_bins.tsv
   convert_fasta_bins_to_biobox_format.py bins/metabat2/*.fa -o bins/metabat2/cami_bins.tsv
   convert_fasta_bins_to_biobox_format.py bins/semibin2/output_bins/*.fa -o bins/semibin2/cami_bins.tsv
   convert_fasta_bins_to_biobox_format.py bins/dastool/dastool_DASTool_bins/* -o bins/dastool/cami_bins.tsv

   sed -i -e 's/@SampleID:_SAMPLEID_/@SampleID:sample_21/' bins/metadecoder/cami_bins.tsv
   sed -i -e 's/@SampleID:_SAMPLEID_/@SampleID:sample_21/' bins/metabat2/cami_bins.tsv
   sed -i -e 's/@SampleID:_SAMPLEID_/@SampleID:sample_21/' bins/semibin2/cami_bins.tsv
   sed -i -e 's/@SampleID:_SAMPLEID_/@SampleID:sample_21/' bins/dastool/cami_bins.tsv

   # Prepare the list of binning files (contig-to-bin mapping files)
   binning_files=(
     "${session_path}/mag_practical/bins/metadecoder/cami_bins.tsv"
     "${session_path}/mag_practical/bins/metabat2/cami_bins.tsv"
     "${session_path}/mag_practical/bins/semibin2/cami_bins.tsv"
     "${session_path}/mag_practical/bins/dastool/cami_bins.tsv"
   )

   # Output directory for AMBER results
   amber_output_dir="evaluation/amber"
   mkdir -p "${amber_output_dir}"

   # Run AMBER
   amber.py \
     -g gold_standard.tsv \
     -l "${labels}" \
     -o "${amber_output_dir}" \
     -x 50,70,90 \
     -y 10,5 \
     "${binning_files[@]}"

**Step 2: View AMBER Report**

Open the HTML report generated by AMBER:

For simplicities sake it wikk be provded via Slack.

**Questions**

- **Q7:** Which binner performed the best according to AMBER?
- **Q8:** How does the refined binning result from DAStool compare to individual binners?

Task 4: Interpret Evaluation Metrics
------------------------------------

**Step 1: Understand Key Metrics**

AMBER provides several metrics:

- **Precision:** The proportion of correctly binned contigs out of all contigs assigned to bins.
- **Recall:** The proportion of contigs from a genome that were correctly binned.
- **F1-score:** The harmonic mean of precision and recall.
- **Adjusted Rand Index (ARI):** Measures the similarity between the clustering result and the gold standard.

**Questions**

- **Q9:** What does a high precision but low recall indicate?
- **Q10:** Why is the F1-score a useful metric?

**Step 2: Analyze the Results**

- **Q11:** Based on the metrics, which tool would you recommend for binning?
- **Q12:** How did DAStool's refinement affect the overall binning performance?

**Step 3: Consider the Impact of Filters**

AMBER allows filtering of bins based on completeness and contamination thresholds using `-x` and `-y` options.

- **Q13:** How do different completeness and contamination thresholds affect the evaluation?
- **Q14:** Why might you want to adjust these thresholds?

**Notes**

- Evaluating binning results against a gold standard helps validate the accuracy of the methods.
- Consider both completeness and contamination when assessing bin quality.

Task 5: Advanced AMBER Usage (Optional)
----------------------------------------

**Step 1: Use Additional Options**

Explore additional options in AMBER, such as filtering out the smallest genome bins or removing specific genomes.

.. code-block:: bash

   amber.py \
     -g gold_standard.tsv \
     -l "${labels}" \
     -p 1 \
     -o "${amber_output_dir}" \
     "${binning_files[@]}"

- The `-p` option filters out the smallest 1% genome bins.

**Questions**

- **Q15:** How does filtering out small bins affect the evaluation metrics?
- **Q16:** When might this be useful?

**Step 2: Include Descriptions and Colors**

Add descriptions and custom colors to the AMBER report.

.. code-block:: bash

   amber.py \
     -g gold_standard.tsv \
     -l "${labels}" \
     -d "MAG Binning Evaluation" \
     --colors "#1f77b4,#ff7f0e,#2ca02c,#d62728" \
     -o "${amber_output_dir}" \
     "${binning_files[@]}"

**Notes**

- Customizing the report can make it easier to interpret and present the results.
- Ensure that the number of colors matches the number of binning results.

**Congratulations!**

You have successfully evaluated your binning results using AMBER. Understanding how your bins compare to a gold standard is crucial for assessing the effectiveness of different binning tools and refinement strategies.

**End of Practical**

---

**Additional Notes:**

- Make sure that all paths used in the code blocks correspond to your actual directory structure.
- Replace any placeholder variables with your actual values if they differ.
- If you encounter any issues with running AMBER, refer to the official AMBER documentation for troubleshooting.
- Ensure that you have sufficient computational resources, as running AMBER on large datasets can be resource-intensive.

---

**References**

- AMBER GitHub Repository: https://github.com/CAMI-challenge/AMBER
- AMBER Documentation: https://cami-challenge.github.io/AMBER/

